{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robles_hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisOmics/MachineLearning/blob/master/CNN_DNN_bigdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here I create a DNN followed by a DNN for image classification from a large dataset \n",
        "## 1 - Intro\n",
        "We will be using the  CIFAR-10 dataset\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
        "We will train a DNN followed by a CNN and test the accuracy.\n",
        "## 2 - Downloading the data and installing dependencies"
      ],
      "metadata": {
        "id": "UbQPpM0leGTK"
      }
    },
    {
      "metadata": {
        "id": "7u_3MXVYakMO",
        "outputId": "42ed7273-ef7c-41f4-9e27-453b0e866e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131323 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "\u001b[K    100% |████████████████████████████████| 530.8MB 53.8MB/s \n",
            "4/CwFpDH2r0-QmF7DTOm5t_99sZ2DGyWxR7k5Khd3bUTPztMzf3Aq_CqY\n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "4/CwFpDH2r0-QmF7DTOm5t_99sZ2DGyWxR7k5Khd3bUTPztMzf3Aq_CqY\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aBYBJsNWDfxt",
        "outputId": "dab93925-c510-4ba4-de5c-b4d23c4c5a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --upgrade --force-reinstall -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "!pip3 install https://download.pytorch.org/whl/cu80/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 484.0MB 65.7MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 1.8MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 13.1MB/s \n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.0.1.post2 from https://download.pytorch.org/whl/cu80/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu80/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl (530.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 530.8MB 30kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 0.4.0\n",
            "    Uninstalling torch-0.4.0:\n",
            "      Successfully uninstalled torch-0.4.0\n",
            "Successfully installed torch-1.0.1.post2\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1.post2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Torch 1.0.1.post2 CUDA 8.0.61\n",
            "Device: cuda:0\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.utils.data as td\n",
        "import random,time, sys"
      ],
      "metadata": {
        "id": "ytRbntMoedVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Downlaoding Training and Test Data"
      ],
      "metadata": {
        "id": "jekmiJIlg5hG"
      }
    },
    {
      "metadata": {
        "id": "1TxCIlAyaryU",
        "outputId": "2b18750d-e9a5-47e0-8089-0af815da5826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def cifar_loaders(batch_size, shuffle_test=False): \n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.225, 0.225, 0.225])\n",
        "    train = datasets.CIFAR10('./', train=True, download=True, \n",
        "        transform=transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32, 4),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "    test = datasets.CIFAR10('./', train=False, \n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
        "        shuffle=True, pin_memory=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size,\n",
        "        shuffle=shuffle_test, pin_memory=True)\n",
        "    return train_loader, test_loader\n",
        "  \n",
        "\n",
        "batch_size = 64\n",
        "test_batch_size = 64\n",
        "\n",
        "train_loader, _ = cifar_loaders(batch_size)\n",
        "_, test_loader = cifar_loaders(test_batch_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 170483712/170498071 [07:44<00:00, 108057.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Creating DNN and testing accuracy"
      ],
      "metadata": {
        "id": "gGrLySn2hOJN"
      }
    },
    {
      "metadata": {
        "id": "TMWkhE89ar1Z"
      },
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__() #load super class for training data\n",
        "        self.fc1 = nn.Linear(3072, 1000) #defining fully connected with input 3072 (3x32x32 pixels) and output 320\n",
        "        self.fc2 = nn.Linear(1000, 540) #defining fully connected with input 1000 and output 540\n",
        "        self.fc3 = nn.Linear(540, 300) #defining fully connected\n",
        "        self.fc4 = nn.Linear(300, 270)\n",
        "        self.fc5 = nn.Linear(270, 150)\n",
        "        self.fc6 = nn.Linear(150, 50)\n",
        "        self.fc7 = nn.Linear(50, 10)\n",
        "        self.relu = nn.ReLU() #defining Rectified Linear Unit as activation function\n",
        "\n",
        "    def forward(self, x): #feed forward\n",
        "        layer1 = x.view(-1, 3072) #make it flat in one dimension from 0 - 784\n",
        "        layer2 = self.relu(self.fc1(layer1)) #layer2 = layer1 -> fc1 -> relu\n",
        "        layer3 = self.relu(self.fc2(layer2)) #layer3 = layer2 -> fc2 -> relu\n",
        "        layer4 = self.relu(self.fc3(layer3)) #layer4 = layer3 -> fc2 -> relu\n",
        "        layer5 = self.relu(self.fc4(layer4)) #layer2 = layer1 -> fc1 -> relu\n",
        "        layer6 = self.relu(self.fc5(layer5)) #layer3 = layer2 -> fc2 -> relu\n",
        "        layer7 = self.relu(self.fc6(layer6))\n",
        "        layer8 = self.relu(self.fc7(layer7))\n",
        "        return layer8 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PmFjm6lJBcbs",
        "outputId": "90d9f85a-8f19-4230-9f14-f86f884c1800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "net=DNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epoch_loss_all=[]\n",
        "net.to(device)\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # print statistics\n",
        "        epoch_loss += float(loss.item())\n",
        "    print('[epoch %d, batch %5d] loss: %.8f' %(epoch + 1, i + 1, epoch_loss/(i + 1)))\n",
        "    epoch_loss_all.append(epoch_loss/(i + 1))\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1, batch   782] loss: 2.30274210\n",
            "[epoch 2, batch   782] loss: 2.30170476\n",
            "[epoch 3, batch   782] loss: 2.29998546\n",
            "[epoch 4, batch   782] loss: 2.29248874\n",
            "[epoch 5, batch   782] loss: 2.24742164\n",
            "[epoch 6, batch   782] loss: 2.20125571\n",
            "[epoch 7, batch   782] loss: 2.18846756\n",
            "[epoch 8, batch   782] loss: 2.17097623\n",
            "[epoch 9, batch   782] loss: 2.14683260\n",
            "[epoch 10, batch   782] loss: 2.12488738\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RzSBfoclI1xp",
        "outputId": "cb06bc29-1f89-43cc-889e-1c7386646a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Creating CNN and testing accuracy"
      ],
      "metadata": {
        "id": "Dy4eQrMchfAg"
      }
    },
    {
      "metadata": {
        "id": "X5RzOohrIgx5"
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(CNN, self).__init__() #load super class for training data\n",
        "\t\tself.conv1 = nn.Conv2d(3, 10, kernel_size=3, stride=2, padding=1) #Convolutional modul: input 3, output 10, kernel 5\n",
        "\t\tself.conv2 = nn.Conv2d(10, 12, kernel_size=2, stride=1, padding=1) #Convolutional modul: input 10, output 20, kernel 5\n",
        "\t\tself.conv3 = nn.Conv2d(12, 8, kernel_size=2, stride=2, padding=2)\n",
        "\t\tself.conv4 = nn.Conv2d(8, 64, kernel_size=3, stride=1, padding=0) \n",
        "\t\tself.relu = nn.ReLU() #activation relu modul\n",
        "\t\tself.fc1 = nn.Linear(4096, 200) #Fully Connected modul: input, output\n",
        "\t\tself.fc2 = nn.Linear(200, 50)# Fully Connected modul: input, output\n",
        "\t\tself.fc3 = nn.Linear(50, 10)# Fully Connected modul: input, output\n",
        "\n",
        "\tdef forward(self, x): #feed forward\n",
        "\t\tlayer1 = self.relu((self.conv1(x))) # layer1 = x -> conv1 -> maxpool -> relu\n",
        "\t\tlayer2 = self.relu((self.conv2(layer1))) # layer1 = x -> conv1 -> maxpool -> relu\n",
        "\t\tlayer3 = self.relu((self.conv3(layer2)))# layer1 = x -> conv1 -> maxpool -> relu\n",
        "\t\tlayer4 = self.relu((self.conv4(layer3))) # layer1 = x -> conv1 -> maxpool -> relu\n",
        "\t\t#print(layer4.size())\n",
        "    \n",
        "\t\tlayer4 = layer4.view(-1, 4096)\n",
        "\t\tlayer5 = self.relu(self.fc1(layer4)) #layer4 = layer3 -> fc1 -> relu\n",
        "\t\tlayer6 = self.relu(self.fc2(layer5)) #layer4 = layer3 -> fc1 -> relu\n",
        "\t\tlayer7 = self.fc3(layer6) #layer5 = layer4 -> fc2\n",
        "\t\treturn layer7\n",
        "        #return F.log_softmax(layer5) #softmax activation to layer5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMl2fW7WPu3O",
        "outputId": "1f11d414-049b-4bca-e7bf-713add2cda4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "def inout(inw=32, kernel=2, stride=2, pad=1):\n",
        "  outwidth = (inw + 2 * pad - (kernel - 1) -1)/stride + 1\n",
        "  print(\"outwidth =  %i\" %outwidth)\n",
        "\n",
        "  \n",
        "inout(32, 3, 2, 1)\n",
        "inout(16, 2, 1, 1)\n",
        "inout(17, 2, 2, 2)\n",
        "inout(10, 3, 1, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outwidth =  16\n",
            "outwidth =  17\n",
            "outwidth =  10\n",
            "outwidth =  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lz9I3aOgEfyG",
        "outputId": "4be2d0c4-6c4e-486c-edab-e8c6ff895026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "net2=CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9, nesterov=True, weight_decay=0.0005)\n",
        "epoch_loss_all=[]\n",
        "net2.to(device)\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    start = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # print statistics\n",
        "        epoch_loss += float(loss.item())\n",
        "    print('[epoch %d] loss: %.8f time: %f' %(epoch + 1, epoch_loss/(i + 1), time.time() - start))\n",
        "    epoch_loss_all.append(epoch_loss/(i + 1))\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1] loss: 2.30390039 time: 19.161966\n",
            "[epoch 2] loss: 2.30144435 time: 19.300143\n",
            "[epoch 3] loss: 2.28721505 time: 19.110650\n",
            "[epoch 4] loss: 2.12755660 time: 19.309396\n",
            "[epoch 5] loss: 1.96700541 time: 19.202543\n",
            "[epoch 6] loss: 1.85664379 time: 19.118961\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}